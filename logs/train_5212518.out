Job ID: 5212518
Job Name: ehr_e20_lr0.0001
Node: ccc0387
CUDA_VISIBLE_DEVICES: 0
Start Time: Fri Oct 10 01:52:25 CDT 2025
Working Directory: /u/jalenj4/pehr_scratch
Fri Oct 10 01:52:25 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:01:00.0 Off |                    0 |
| N/A   45C    P0             66W /  500W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Parameters:
  NUM_PATIENTS: 3000
  BATCH_SIZE: 16
  NUM_EPOCHS: 20
  LEARNING_RATE: 0.0001
  GENERATION_TEMP: 1.0
  TOP_K: 50
INFO: === EHR Generation Training Started ===
INFO: Configuration: {'model_name': 'facebook/bart-base', 'num_patients': 3000, 'max_seq_length': 256, 'batch_size': 16, 'num_epochs': 20, 'learning_rate': 0.0001, 'generation_temp': 1.0, 'generation_max_length': 256, 'num_warmup_steps': 0, 'top_k': 50, 'data_dir': 'data_files', 'mimic_paths': {'patients_path': 'data_files/PATIENTS.csv', 'admissions_path': 'data_files/ADMISSIONS.csv', 'diagnoses_path': 'data_files/DIAGNOSES_ICD.csv'}}
INFO: Using device: cuda
INFO: Loading pretrained BART model: facebook/bart-base
INFO: Added 4 special tokens: <demo>, <v>, <\v>, <END>
INFO: Resized model embeddings to 50269 tokens
INFO: Initialized 4 new embeddings from pretrained mean
INFO: Loading MIMIC-III data files
INFO: Loaded 46520 patients
INFO: Loaded 58976 admissions
INFO: Loaded 651047 diagnosis records
INFO: Data processing complete. Formatting sequences...
INFO: Sequence formatting complete. Generated 3000 patient sequences
INFO: Average visits per patient: 1.27
INFO: Average tokens per sequence: 19.69
INFO: Sample patient sequences:
INFO: Sample 1: 41 WHITE F <demo> <v> 86405 80709 8244 E8150 <\v> <END>...
INFO: Sample 2: 0 WHITE M <demo> <v> V3001 76518 7742 7793 76527 77081 77981 V502 V053 V290 <\v> <END>...
INFO: Sample 3: 36 WHITE F <demo> <v> 430 07054 72989 2768 49390 53081 3051 <\v> <END>...
INFO: Sample 4: 52 BLACK/AFRICAN AMERICAN F <demo> <v> 4019 2720 58389 25000 4412 2859 V1581 <\v> <v> 99662 5856 4592 40391 4538 E8791 41401 25201 2720 28521 32723 V4...
INFO: Sample 5: 0 WHITE M <demo> <v> V3100 76517 76528 7756 76407 <\v> <END>...
INFO: Created dataset with 3000 samples, 188 batches
INFO: Optimizer: AdamW with lr=0.0001
INFO: Scheduler: linear with 0 warmup steps
INFO: Starting model training for 20 epochs
INFO: Training steps: 3760
INFO: Device: cuda
INFO: Epoch 1/20 completed | Avg Loss: 0.6163
INFO: Epoch 2/20 completed | Avg Loss: 0.0609
INFO: Epoch 3/20 completed | Avg Loss: 0.0155
INFO: Epoch 4/20 completed | Avg Loss: 0.0105
INFO: Epoch 5/20 completed | Avg Loss: 0.0117
INFO: Epoch 6/20 completed | Avg Loss: 0.0081
INFO: Epoch 7/20 completed | Avg Loss: 0.0135
INFO: Epoch 8/20 completed | Avg Loss: 0.0067
INFO: Epoch 9/20 completed | Avg Loss: 0.0086
INFO: Epoch 10/20 completed | Avg Loss: 0.0048
INFO: Epoch 11/20 completed | Avg Loss: 0.0063
INFO: Epoch 12/20 completed | Avg Loss: 0.0043
INFO: Epoch 13/20 completed | Avg Loss: 0.0023
INFO: Epoch 14/20 completed | Avg Loss: 0.0019
INFO: Epoch 15/20 completed | Avg Loss: 0.0032
INFO: Epoch 16/20 completed | Avg Loss: 0.0016
INFO: Epoch 17/20 completed | Avg Loss: 0.0016
INFO: Epoch 18/20 completed | Avg Loss: 0.0015
INFO: Epoch 19/20 completed | Avg Loss: 0.0010
INFO: Epoch 20/20 completed | Avg Loss: 0.0008
INFO: Training complete
INFO: Final average loss: 0.0008
INFO: === Generating synthetic patient data ===
INFO: 
--- Sample 1/5 ---
INFO: Generating sequence for prompt: '79 ASIAN F <demo>'
INFO: Starting generation with temp=1.0, top_k=50, max_length=256
INFO: Generated token counts - <v>: 1, <\v>: 0, <END>: 1
INFO: Generated sequence (clean): 79 ASIAN F  79 ASIAN M  
INFO: 
--- Sample 2/5 ---
INFO: Generating sequence for prompt: '23 UNKNOWN/NOT SPECIFIED M <demo>'
INFO: Starting generation with temp=1.0, top_k=50, max_length=256
INFO: Generated token counts - <v>: 1, <\v>: 1, <END>: 1
INFO: Generated sequence (clean): 23 UNKNOWN/NOT SPECIFIED M  23 UNKNOWN /NOT SPECIFIC M  
INFO: 
--- Sample 3/5 ---
INFO: Generating sequence for prompt: '68 UNKNOWN/NOT SPECIFIED F <demo>'
INFO: Starting generation with temp=1.0, top_k=50, max_length=256
INFO: Generated token counts - <v>: 1, <\v>: 1, <END>: 1
INFO: Generated sequence (clean): 68 UNKNOWN/NOT SPECIFIED F  667 UNKNOWN/.NOT SPECIFIC F  
INFO: 
--- Sample 4/5 ---
INFO: Generating sequence for prompt: '83 ASIAN F <demo>'
INFO: Starting generation with temp=1.0, top_k=50, max_length=256
INFO: Generated token counts - <v>: 1, <\v>: 0, <END>: 1
INFO: Generated sequence (clean): 83 ASIAN F  81881 ASIAN M  
INFO: 
--- Sample 5/5 ---
INFO: Generating sequence for prompt: '32 HISPANIC OR LATINO M <demo>'
INFO: Starting generation with temp=1.0, top_k=50, max_length=256
INFO: Generated token counts - <v>: 1, <\v>: 1, <END>: 1
INFO: Generated sequence (clean): 32 HISPANIC OR LATINO M  788 M  
INFO: === Training and generation complete ===
End Time: Fri Oct 10 02:08:11 CDT 2025
Exit Code: 0
